# ============================================
# LocalTopSH Configuration
# ============================================
# For production: use Docker Secrets (see secrets/ folder)
# For local dev: use this .env file
# ============================================

# LLM API (only for local dev - in prod use proxy)
BASE_URL=http://localhost:8000/v1
MODEL_NAME=openai/gpt-oss-120b
API_KEY=sk-your-api-key

# Telegram Bot (only for local dev - in prod use secret)
TELEGRAM_TOKEN=your-telegram-bot-token
ALLOWED_USERS=123456789

# Search API (only for local dev - in prod use proxy)
ZAI_API_KEY=your-zai-api-key

# Gateway settings
MCP_PORT=3100
MCP_URL=http://localhost:3100
WORKSPACE=/workspace

# Network - port range for user services
EXPOSED_PORTS=4000-4999

# Max concurrent users
MAX_CONCURRENT_USERS=10

# ============================================
# PRODUCTION (Docker Compose):
# Secrets are in ./secrets/ folder:
#   - telegram_token.txt
#   - base_url.txt
#   - api_key.txt
#   - zai_api_key.txt
#
# Gateway container gets:
#   - PROXY_URL=http://proxy:3200
#   - TELEGRAM_TOKEN from /run/secrets/
#
# Proxy container gets:
#   - All API keys from /run/secrets/
#
# Agent NEVER sees API keys!
# ============================================

# ============================================
# macOS / Local Development Settings
# ============================================

# Admin panel port (default: 3000)
# Change if port 3000 is already in use (common on macOS)
ADMIN_PORT=3000

# Logging
LOG_LEVEL=INFO
LOG_RAW=false

# Access Control
ACCESS_MODE=admin
ADMIN_USER_ID=your-telegram-user-id
